---
layout: post
title:  Deep Unsupervised Learning using Nonequilibrium Thermodynamics
date: 2023-12-03 20:36:00
description: 
tags: Literature-notes
categories: Diffusion-models
tikzjax: true
---

# Preliminiaries
- use a Markov chain to gradually convert one distribution into another

- Ideas: Estimating small perturbations is more tractable than explicitly describing the full distribution with a single, non-analytically-normalizable, potential function

- Ideas from quasi-static processes, and **annealed** **importance sampling**

- **Jarzynski equality (Annealed Importance Sampling (AIS)): **use a Markov chain which slowly converts one distribution into another to compute a ratio of normalizing constants.

- Diffusion in the context of statistics refers to transforming a complex distribution $$p_{\text{complex}}$$on $$\mathbb{R}^{d}$$to a simple distribution $$p_{\text{prior}}$$on the same domain. $$\mathbf{x}_0 \sim p_{\text{complex}} \Rightarrow \mathcal{T} (\mathbf{x}_0) \sim p_{\text{prior}}$$

- By repeated application of a transition kernel $$q(\mathbf{x}\vert \mathbf{x}')$$on the samples of any distribution would lead to samples from $$p_{\text{prior}}(\mathbf{x})$$if the following holds: $$p_{\text{prior}}(\textbf{x}) = \int q \mathbf{(x \vert x'} )p_{\text{prior}}\mathbf{x}'d \mathbf{x}'$$

- Define $$\mathcal{T}$$ to be repeated application of the transition kernel $$\mathbf{q}(\mathbf{x} \vert \mathbf{x}')$$over discrete $$t$$, $$\mathbf{x}_t \sim q(\mathbf{x} \vert \mathbf{x}' = \mathbf{x}_{t-1}), \, \forall t>0$$ we have $$\mathbf{x}_{\infty} \sim p_{\text{prior}}$$

- One attractive choice of $$\{ q, p_{\text{prior}} \}$$pair due to its simiplicity and tractability

   - $$q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) = \mathcal{N} (\mathbf{x}_t; \sqrt{1- \beta_t}\mathbf{x}_{t-1}, \beta_t \mathbf{I})$$

   - $$q(\mathbf{x}_T) = p_{prior}(\mathbf{x}_T) = \mathcal{N} (\mathbf{x}_T; \mathbf{0, I})$$

   - It is known as Gaussian Diffusion

   - Notice: the diffusion process does not depend on the initial density

   - Forward diffusion process: $$\mathbf{x}_0 \sim p_{\text{data}} \Rightarrow \mathcal{T} (\mathbf{x}_0) \sim \mathcal{N} (\mathbf{0, I})$$

   - Reverse diffusion proccess: $$\mathbf{x}_T \sim \mathcal{N} (\mathbf{0, I})  \Rightarrow \mathcal{T}^{-1} (\mathbf{x}_T) \sim p_{\text{data}}$$

   - $$q(\mathbf{x}_t \vert \mathbf{x}_{t-1})$$is a Gaussian $$\Rightarrow$$$$q(\mathbf{x}_{t-1} \vert \mathbf{x}_{t})$$is a Gaussian, so we only need to know $$\mathbf{f}_{\mu}(\mathbf{x}_{t}, t)$$and $$\mathbf{f}_{\Sigma}(\mathbf{x}_{t}, t)$$for the reverse Markov transitions.

# DPM

Forward (diffusion): $$ q(\mathbf{x}_{t}\mid\mathbf{x}_{t-1})$$

Reverse (parametric): $$ p_{\theta}(\mathbf{x}_{t-1}\mid\mathbf{x}_{t})$$

## Parameterize the mean and convariance

In the DPM, we need to parameterize the  mean $$\mathbf{\mu}_{\theta}(\mathbf{x}_{t},t)$$ and covariance $$\mathbf{\Sigma}_{\theta}(\mathbf{x}_{t},t)$$

Starting from Gaussian noise to gradually remove local perturbations. 

Therefore the reverse process starts with our given tractable distribution $$p(\mathbf{x}_{T})=\pi(\mathbf{x}_{T})$$ and is described as
$$p_{\theta}(\mathbf{x}_{0:T}) =  p(\mathbf{x}_{T}) \prod_{t=1}^{T} p_{\theta}(\mathbf{x}_{t-1}\mid\mathbf{x}_{t})$$

During learning, only the mean and covariancce for a Gaussian diffusion kernel needs to be trained

$$p_{\theta}(\mathbf{x}_{t-1}\mid\mathbf{x}_{t}) = \mathcal{N}(\mathbf{x}_{t-1} ; \mathbf{\mu}_{\theta}(\mathbf{x}_{t},t),\mathbf{\Sigma}_{\theta}(\mathbf{x}_{t},t))$$

The two functions defining the mean $$\mathbf{\mu}_{\theta}(\mathbf{x}_{t},t)$$ and covariance $$\mathbf{\Sigma}_{\theta}(\mathbf{x}_{t},t)$$ can be parametrized by deep neural networks. 

## Loss function

$$\begin{align}
\mathbb{E}_q\left[-\log p_{\theta}(\mathbf{x}_{0}) \right] & \leq \mathbb{E}_{q}\left[-\log \frac{p_{\theta}(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} \mid \mathbf{x}_{0})} \right] 
\end{align}$$

Define:
$$\mathcal{L}  = \mathbb{E}_{q}\left[ -\log p(\mathbf{x}_{T}) - \sum_{t\geq 1} \log \frac{p_{\theta}(\mathbf{x}_{t-1}\mid\mathbf{x}_{t})}{q(\mathbf{x}_{t}\mid\mathbf{x}_{t-1})} \right]$$

this loss is shown to be reducible to

$$\begin{align}
K = -\mathbb{E}_{q}[ &D_{KL}(q(\mathbf{x}_{t-1}\mid\mathbf{x}_{t},\mathbf{x}_{0}) \Vert p_{\theta}(\mathbf{x}_{t-1}\mid\mathbf{x}_{t}))  \\
&+ H_{q}(\mathbf{X}_{T}\vert\mathbf{X}_{0}) - H_{q}(\mathbf{X}_{1}\vert\mathbf{X}_{0}) - H_{p}(\mathbf{X}_{T})]
\end{align}$$
