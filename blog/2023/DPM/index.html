<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="preliminiaries">Preliminiaries</h1> <ul> <li>use a Markov chain to gradually convert one distribution into another</li> <li>Ideas: Estimating small perturbations is more tractable than explicitly describing the full distribution with a single, non-analytically-normalizable, potential function</li> <li>Ideas from quasi-static processes, and <strong>annealed</strong> <strong>importance sampling</strong> </li> <li>**Jarzynski equality (Annealed Importance Sampling (AIS)): **use a Markov chain which slowly converts one distribution into another to compute a ratio of normalizing constants.</li> <li>Diffusion in the context of statistics refers to transforming a complex distribution $p_{\text{complex}}$on $\mathbb{R}^{d}$to a simple distribution $p_{\text{prior}}$on the same domain. $\mathbf{x}<em>0 \sim p</em>{\text{complex}} \Rightarrow \mathcal{T} (\mathbf{x}<em>0) \sim p</em>{\text{prior}}$</li> <li> <table> <tbody> <tr> <td>By repeated application of a transition kernel $q(\mathbf{x}</td> <td>\mathbf{x}’)$on the samples of any distribution would lead to samples from $p_{\text{prior}}(\mathbf{x})$if the following holds: $p_{\text{prior}}(\textbf{x}) = \int q \mathbf{(x</td> <td>x’} )p_{\text{prior}}\mathbf{x}’d \mathbf{x}’$</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>Define $\mathcal{T}$ to be repeated application of the transition kernel $\mathbf{q}(\mathbf{x}</td> <td>\mathbf{x}’)$over discrete $t$,$\mathbf{x}_t \sim q(\mathbf{x}</td> <td>\mathbf{x}’ = \mathbf{x}<em>{t-1}), \, \forall t&gt;0$ we have $\mathbf{x}</em>{\infty} \sim p_{\text{prior}}$</td> </tr> </tbody> </table> </li> <li>One attractive choice of ${ q, p_{\text{prior}} }$pair due to its simiplicity and tractability <ul> <li> <table> <tbody> <tr> <td>$q(\mathbf{x}_t</td> <td>\mathbf{x}<em>{t-1}) = \mathcal{N} (\mathbf{x}_t; \sqrt{1- \beta_t}\mathbf{x}</em>{t-1}, \beta_t \mathbf{I})$</td> </tr> </tbody> </table> </li> <li>$q(\mathbf{x}<em>T) = p</em>{prior}(\mathbf{x}_T) = \mathcal{N} (\mathbf{x}_T; \mathbf{0, I})$</li> <li>It is known as Gaussian Diffusion</li> <li>Notice: the diffusion process does not depend on the initial density</li> <li>Forward diffusion process: $\mathbf{x}<em>0 \sim p</em>{\text{data}} \Rightarrow \mathcal{T} (\mathbf{x}_0) \sim \mathcal{N} (\mathbf{0, I})$</li> <li>Reverse diffusion proccess: $\mathbf{x}<em>T \sim \mathcal{N} (\mathbf{0, I}) \Rightarrow \mathcal{T}^{-1} (\mathbf{x}_T) \sim p</em>{\text{data}}$</li> <li> <table> <tbody> <tr> <td>$q(\mathbf{x}_t</td> <td>\mathbf{x}<em>{t-1})$is a Gaussian $\Rightarrow$$q(\mathbf{x}</em>{t-1}</td> <td>\mathbf{x}<em>{t})$is a Gaussian, so we only need to know $\mathbf{f}</em>{\mu}(\mathbf{x}<em>{t}, t)$and $\mathbf{f}</em>{\Sigma}(\mathbf{x}_{t}, t)$for the reverse Markov transitions</td> </tr> </tbody> </table> </li> </ul> </li> </ul> <h1 id="dpm">DPM</h1> <p>$\text{forward (diffusion)} : q(\mathbf{x}<em>{t}\mid\mathbf{x}</em>{t-1})$ $\text{reverse (parametric)} : p_{\theta}(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t})$</p> <h2 id="parameterize-the-mean-and-convariance">Parameterize the mean and convariance</h2> <p>In the DPM, we need to parameterize the mean $\mathbf{\mu}<em>{\theta}(\mathbf{x}</em>{t},t)$ and covariance $\mathbf{\Sigma}<em>{\theta}(\mathbf{x}</em>{t},t)$ Starting from Gaussian noise to gradually remove local perturbations. Therefore the reverse process starts with our given tractable distribution $p(\mathbf{x}<em>{T})=\pi(\mathbf{x}</em>{T})$ and is described as $p_{\theta}(\mathbf{x}<em>{0:T}) = p(\mathbf{x}</em>{T}) \prod_{t=1}^{T} p_{\theta}(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t})$ During learning, only the mean and covariancce for a Gaussian diffusion kernel needs to be trained $p_{\theta}(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t}) = \mathcal{N}(\mathbf{x}<em>{t-1} ; \mathbf{\mu}</em>{\theta}(\mathbf{x}<em>{t},t),\mathbf{\Sigma}</em>{\theta}(\mathbf{x}<em>{t},t))$ The two functions defining the mean $\mathbf{\mu}</em>{\theta}(\mathbf{x}<em>{t},t)$ and covariance $\mathbf{\Sigma}</em>{\theta}(\mathbf{x}_{t},t)$ can be parametrized by deep neural networks.</p> <h2 id="loss-function">Loss function</h2> <p>$\begin{align} \mathbb{E}<em>q\left[-\log p</em>{\theta}(\mathbf{x}<em>{0}) \right] &amp; \leq \mathbb{E}</em>{q}\left[-\log \frac{p_{\theta}(\mathbf{x}<em>{0:T})}{q(\mathbf{x}</em>{1:T} \mid \mathbf{x}<em>{0})} \right] \end{align}$ Define: $\mathcal{L} = \mathbb{E}</em>{q}\left[ -\log p(\mathbf{x}<em>{T}) - \sum</em>{t\geq 1} \log \frac{p_{\theta}(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t})}{q(\mathbf{x}<em>{t}\mid\mathbf{x}</em>{t-1})} \right]$ this loss is shown to be reducible to $\begin{align} K = -\mathbb{E}<em>{q}[ &amp;D</em>{KL}(q(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t},\mathbf{x}<em>{0}) \Vert p</em>{\theta}(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t})) <br> &amp;+ H_{q}(\mathbf{X}<em>{T}\vert\mathbf{X}</em>{0}) - H_{q}(\mathbf{X}<em>{1}\vert\mathbf{X}</em>{0}) - H_{p}(\mathbf{X}_{T})] \end{align}$</p> </body></html>