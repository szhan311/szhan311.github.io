<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Score-based generative modeling with critically-damped Langevin diffusion | Shaorong Zhang (张少荣)</title> <meta name="author" content="Shaorong R. Zhang"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link defer rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css"> <script defer src="https://tikzjax.com/v1/tikzjax.js"></script> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://szhan311.github.io//blog/2023/CLD/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Shaorong Zhang (张少荣)</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">photo gallery</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Score-based generative modeling with critically-damped Langevin diffusion</h1> <p class="post-meta">December 7, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/literature-review"> <i class="fa-solid fa-hashtag fa-sm"></i> Literature-review</a>     ·   <a href="/blog/category/diffusion-models"> <i class="fa-solid fa-tag fa-sm"></i> Diffusion-models</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="ideas">Ideas</h1> <ul> <li> <p>The diffusion process is the key to improve <strong>synthesis quality</strong> or** sampling speed**.</p> </li> <li> <p>Inspired by <strong>statistical mechanics.</strong></p> </li> <li> <p>The score of the conditional distribution \(p_t(\boldsymbol{v}_t \vert \boldsymbol{x}_t)\) is an arguably easier task than learning the score of \(p_t(\boldsymbol{x}_t)\).</p> </li> </ul> <h1 id="background">Background</h1> <ul> <li> <p>The forward process: \(d \mathbf{u}_t=\boldsymbol{f}\left(\mathbf{u}_t, t\right) d t+\boldsymbol{G}\left(\mathbf{u}_t, t\right) d \mathbf{w}_t, \quad t \in[0, T]\)</p> </li> <li> <p>The backward process: \(d \overline{\mathbf{u}}_t=\left[-\boldsymbol{f}\left(\overline{\mathbf{u}}_t, T-t\right)+\boldsymbol{G}\left(\overline{\mathbf{u}}_t, T-t\right) \boldsymbol{G}\left(\overline{\mathbf{u}}_t, T-t\right)^{\top} \nabla_{\overline{\mathbf{u}}_t} \log p_{T-t}\left(\overline{\mathbf{u}}_t\right)\right] d t+\boldsymbol{G}\left(\overline{\mathbf{u}}_t, T-t\right) d \mathbf{w}_t\)</p> </li> <li> <p>Currently used SDEs have drift and diffusion coefficients of the symple form: \(\boldsymbol{f}\left(\mathbf{x}_t, t\right)=f(t) \mathbf{x}_t\) and \(\boldsymbol{G}\left(\mathbf{x}_t, t\right)=g(t) \boldsymbol{I}_d\)</p> </li> <li> <p>Generally, setting \(p\left(\mathbf{u}_0\right)=p_{\text {data }}(\mathbf{x})\), \(p\left(\mathbf{u}_T\right)= \mathcal{N}(\boldsymbol{0}, \boldsymbol{I}_d)\).</p> </li> <li> <p>If \(\boldsymbol{f}\) and \(\boldsymbol{G}\) take the simple form above, the denoising score matching objective is: \(\min _{\boldsymbol{\theta}} \mathbb{E}_{t \sim \mathcal{U}[0, T]} \mathbb{E}_{\mathbf{x}_0 \sim p\left(\mathbf{x}_0\right)} \mathbb{E}_{\mathbf{x}_t \sim p_t\left(\mathbf{x}_t \mid \mathbf{x}_0\right)}\left[\lambda(t)\left\|\mathbf{s}_{\boldsymbol{\theta}}\left(\mathbf{x}_t, t\right)-\nabla_{\mathbf{x}_t} \log p_t\left(\mathbf{x}_t \mid \mathbf{x}_0\right)\right\|_2^2\right]\)</p> </li> <li> <p>If \(\boldsymbol{f}\) and \(\boldsymbol{G}\) are affine, the conditional distribution \(p_t\left(\mathbf{x}_t \mid \mathbf{x}_0\right)\) is Normal and avaiable analytically.</p> </li> </ul> <h1 id="critically-damped-langevin-dynamic">Critically-damped Langevin Dynamic</h1> <ul> <li>We propose to augment the data \(\mathbf{x}_t \in \mathbb{R}^d\) and \(\mathbf{v}_t \in \mathbb{R}^d\). With \(\mathbf{u}_t=\left(\mathbf{x}_t, \mathbf{v}_t\right)^{\top} \in \mathbb{R}^{2 d}\), we set</li> <li> \[\boldsymbol{f}\left(\mathbf{u}_t, t\right):=\left(\left(\begin{array}{cc}0 &amp; \beta M^{-1} \\ -\beta &amp; -\Gamma \beta M^{-1}\end{array}\right) \otimes \boldsymbol{I}_d\right) \mathbf{u}_t, \quad \boldsymbol{G}\left(\mathbf{u}_t, t\right):=\left(\begin{array}{cc}0 &amp; 0 \\ 0 &amp; \sqrt{2 \Gamma \beta}\end{array}\right) \otimes \boldsymbol{I}_d\] </li> <li> <p>The coupled SDE that describes the diffusion process: \(\left(\begin{array}{l}d \mathbf{x}_t \\ d \mathbf{v}_t\end{array}\right)=\underbrace{\left(\begin{array}{c}M^{-1} \mathbf{v}_t \\ -\mathbf{x}_t\end{array}\right) \beta d t}_{\text {Hamiltonian component }=: H}+\underbrace{\left(\begin{array}{c}\mathbf{0}_d \\ -\Gamma M^{-1} \mathbf{v}_t\end{array}\right) \beta d t+\left(\begin{array}{c}0 \\ \sqrt{2 \Gamma \beta}\end{array}\right) d \mathbf{w}_t}_{\text {Ornstein-Uhlenbeck process=:O }}\)</p> </li> <li> <p>The mass \(M \in \mathbb{R}^+\) is a hyperparameter that determines the coupling between the \(\mathbf{x}_t\)and \(\mathbf{v}_t\) variables.</p> </li> <li> <p>\(\beta \in \mathbb{R}^+\) is a constant time rescaling chosen such that the diffusion <strong>converges to its equilibrium distribution</strong> (we found constant \(\beta\)’s to work well).</p> </li> <li> <p>\(\Gamma \in \mathbb{R}^+\) is a friction coefficient that determines <strong>the strength of the noise injection</strong> into the velocities.</p> </li> <li> <p>The Hamiltonian component plays a role to <strong>accelerate sampling</strong> and <strong>efﬁciently explore complex probability distributions</strong>.</p> </li> <li> <p>The \(O\) term corresponds to an <strong>Ornstein-Uhlenbeck process</strong> in the velocity, which injects noise such that the diffusion dynamics properly converge to equilibrium for any \(\Gamma &gt; 0\).</p> </li> <li> <p>It can be shown that the equilibrium distribution of this diffusion is \(p_{\mathrm{EQ}}(\mathbf{u})=\mathcal{N}\left(\mathbf{x} ; \mathbf{0}_d, \boldsymbol{I}_d\right) \mathcal{N}\left(\mathbf{v} ; \mathbf{0}_d, M \boldsymbol{I}_d\right)\)</p> </li> <li> <p>The balance between \(M\) and \(\Gamma\)</p> <ul> <li> <p>For \(\Gamma^2 &lt; 4M\)(underdamped Langevin dynamics): oscillatory dynamics of \(\mathbf{x}_t\) and \(\boldsymbol{v}_t\) that slow down converge to equilibrium.</p> </li> <li> <p>For \(\Gamma^2 &gt; 4M\)(overdamped Langevin dynamics): the \(O\) term dominates wihci also slows down convergence.</p> </li> <li> <p>For \(\Gamma^2 = 4M\)(critically-damped Langevin dynamics): an ideal balance is achieved and convergence to \(p_{\mathrm{EQ}}(\mathbf{u})\) as fast as possible in a smooth manner without oscillations.</p> </li> </ul> </li> </ul> <h1 id="score-matching-objective">Score Matching Objective</h1> <ul> <li> <p>we initialize the joint \(\bar{p}\left(\mathbf{u}_0\right)=p\left(\mathbf{x}_0\right) p\left(\mathbf{v}_0\right)=p_{\text {data }}\left(\mathbf{x}_0\right) \mathcal{N}\left(\mathbf{v}_0 ; \mathbf{0}_d, \gamma M \boldsymbol{I}_d\right)\) with hyperparameter \(\gamma &lt; 1\)</p> </li> <li> <p>let the distribution diffuse towards the tractable equilibrium—or prior—distribution \(p_{\mathrm{EQ}}(\mathbf{u})\).</p> </li> <li> <p>The score matching (SM) objective: \(\min _{\boldsymbol{\theta}} \mathbb{E}_{t \sim \mathcal{U}[0, T]} \mathbb{E}_{\mathbf{u}_t \sim p_t\left(\mathbf{u}_t\right)}\left[\lambda(t)\left\|s_{\boldsymbol{\theta}}\left(\mathbf{u}_t, t\right)-\nabla_{\mathbf{v}_t} \log p_t\left(\mathbf{u}_t\right)\right\|_2^2\right]\)</p> </li> <li> \[\nabla_{\mathbf{v}_t} \log p_t\left(\mathbf{u}_t\right)=\nabla_{\mathbf{v}_t}\left[\log p_t\left(\mathbf{v}_t \mid \mathbf{x}_t\right)+\log p_t\left(\mathbf{x}_t\right)\right]=\nabla_{\mathbf{v}_t} \log p_t\left(\mathbf{v}_t \mid \mathbf{x}_t\right)\] </li> <li> <p>Why \(p_t\left(\mathbf{v}_t \mid \mathbf{x}_t\right)\) is eaiser to learn</p> <ul> <li> <p>our velocity distribution is initialized from a simple Normal distribution, such that \(p_t\left(\mathbf{v}_t \mid \mathbf{x}_t\right)\) is closer to a Normal distribution for all \(t \geq 0\) than \(p_t\left( \mathbf{x}_t\right)\) itself.</p> </li> <li> <p>empirically verify the reduced complexity</p> </li> </ul> </li> </ul> <h1 id="hybrid-score-matching">Hybrid score matching</h1> <ul> <li>Objective: \(\min _{\boldsymbol{\theta}} \mathbb{E}_{t \in[0, T]} \mathbb{E}_{\mathbf{x}_0 \sim p_0\left(\mathbf{x}_0\right)} \mathbb{E}_{\mathbf{u}_t \sim p_t\left(\mathbf{u}_t \mid \mathbf{x}_0\right)}\left[\lambda(t)\left\|s_{\boldsymbol{\theta}}\left(\mathbf{u}_t, t\right)-\nabla_{\mathbf{v}_t} \log p_t\left(\mathbf{u}_t \mid \mathbf{x}_0\right)\right\|_2^2\right]\)</li> </ul> <h1 id="score-model-parameterization">Score Model Parameterization</h1> <ul> <li>\(\mathbf{u}_t=\boldsymbol{\mu}_t\left(\mathbf{x}_0\right)+\boldsymbol{L}_t \boldsymbol{\epsilon}_{2 d}\), where \(\boldsymbol{\Sigma}_t=\boldsymbol{L}_t \boldsymbol{L}_t^{\top}\) is the Cholesky decomposition of \(p_t\left(\mathbf{u}_t \mid \mathbf{x}_0\right)\)’s covariance matrix, \(\boldsymbol{\epsilon}_{2 d} \sim \mathcal{N}\left(\boldsymbol{\epsilon}_{2 d} ; \mathbf{0}_{2 d}, \boldsymbol{I}_{2 d}\right)\), and \(\boldsymbol{\mu}_t\left(\mathbf{x}_0\right)\) is \(p_t\left(\mathbf{u}_t \mid \mathbf{x}_0\right)\)’s mean.</li> <li> \[\nabla_{\mathbf{v}_t} \log p_t\left(\mathbf{u}_t \mid \mathbf{x}_0\right)=-\ell_t \boldsymbol{\epsilon}_{d: 2 d}\] </li> <li> <p>With \(\boldsymbol{\Sigma}_t=\underbrace{\left(\begin{array}{cc}\Sigma_t^{x x} &amp; \Sigma_t^{x v} \\ \Sigma_t^{x v} &amp; \Sigma_t^{v v}\end{array}\right)}_{\text {"per-dimension" covariance matrix }} \otimes \boldsymbol{I}_d, \quad\) we have \(\quad \ell_t:=\sqrt{\frac{\Sigma_t^{x x}}{\Sigma_t^{x x} \Sigma_t^{v v}-\left(\Sigma_t^{x v}\right)^2}}\)</p> </li> <li> <p>We parameterize \(s_{\boldsymbol{\theta}}\left(\mathbf{u}_t, t\right)=-\ell_t \alpha_{\boldsymbol{\theta}}\left(\mathbf{u}_t, t\right)\) with \(\alpha_{\boldsymbol{\theta}}\left(\mathbf{u}_t, t\right)=\ell_t^{-1} \mathbf{v}_t / \Sigma_t^{v v}+ \alpha'_{\boldsymbol{\theta}}\left(\mathbf{u}_t, t\right)\), where \(\Sigma_t^{vv}\) corresponds to the \(v-v\) component of the “per-dimension” covariance matrix of the Normal Distribution \(p_t\left(\mathbf{u}_t \mid \mathbf{x}_0=\mathbf{0}_d\right)\)</p> </li> <li> \[\operatorname{HSM}(\lambda(t))=\mathbb{E}_{t \sim \mathcal{U}[0, T], \mathbf{x}_0 \sim p_0\left(\mathbf{x}_0\right), \mathbf{u}_t \sim p_t\left(\mathbf{u}_t \mid \mathbf{x}_0\right)}\left[\lambda(t)\left(\ell_t^{\mathrm{HSM}}\right)^2\left\|\boldsymbol{\epsilon}_{d: 2 d}-\alpha_{\boldsymbol{\theta}}\left(\mathbf{u}_t, t\right)\right\|_2^2\right]\] </li> <li>Training objective: \(\min _{\boldsymbol{\theta}} \mathbb{E}_{t \sim \mathcal{U}[0, T]} \mathbb{E}_{\mathbf{x}_0 \sim p_0\left(\mathbf{x}_0\right)} \mathbb{E}_{\boldsymbol{\epsilon}_{2 d} \sim \mathcal{N}\left(\boldsymbol{\epsilon}_{2 d} ; \mathbf{0}_{2 d}, \boldsymbol{I}_{2 d}\right)}\left[\lambda(t) \ell_t^2\left\|\boldsymbol{\epsilon}_{d: 2 d}-\alpha_{\boldsymbol{\theta}}\left(\boldsymbol{\mu}_t\left(\mathbf{x}_0\right)+\boldsymbol{L}_t \boldsymbol{\epsilon}_{2 d}, t\right)\right\|_2^2\right]\)</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/PSLD/">Phase Space Langevin Diffusion</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/EDM/">Elucidating the Design Space of Diffusion-Based Generative Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/SGM-(NCSN)/">Generative Modeling by Estimating Gradients of the Data Distribution</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Reverse-time-Diffusion-Equation-Models/">Reverse time diffusion equation models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Denoising-Diffusion-Bridge-Models/">Denoising Diffusion Bridge Models</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Shaorong R. Zhang. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.getElementById("WeChatBtn");wechatBtn.onclick=function(){wechatModal.style.display="block"},window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> </body> </html>