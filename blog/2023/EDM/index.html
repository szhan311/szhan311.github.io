<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Elucidating the Design Space of Diffusion-Based Generative Models | Shaorong Zhang (张少荣)</title> <meta name="author" content="Shaorong R. Zhang"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link defer rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css"> <script defer src="https://tikzjax.com/v1/tikzjax.js"></script> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://szhan311.github.io//blog/2023/EDM/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Shaorong Zhang (张少荣)</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">photo gallery</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Elucidating the Design Space of Diffusion-Based Generative Models</h1> <p class="post-meta">December 6, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/literature-review"> <i class="fa-solid fa-hashtag fa-sm"></i> Literature-review</a>     ·   <a href="/blog/category/diffusion-models"> <i class="fa-solid fa-tag fa-sm"></i> Diffusion-models</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="original-ode--sde-formulation-from-previous-work">Original ODE / SDE formulation from previous work</h1> <ul> <li>Song et al. define their forward SDE as: \(dx = f(x,t)dt + g(t) dw_t\), where \(f(\cdot, t):\mathbb{R}^d \rightarrow \mathbb{R}^d\)and \(g(\cdot): \mathbb{R} \rightarrow \mathbb{R}\)are the drift and diffusion coefficients, repsectively, where \(d\)is the dimensionality of the dataset. \(f(\cdot)\)is always of the form</li> </ul> <p>\(f(x, t) = f(t) x\), where \(f(\cdot):\mathbb{R} \rightarrow \mathbb{R}.\)</p> <ul> <li> <p>Thus, the SDE can be equivalently written as\(dx = f(t)x + g(t) d w_t\).</p> </li> <li> <p>The pertubation kernels of this SDE have the general form \(p_{0t}(x(t) \vert x(0)) = \mathcal{N} (x(t); s(t)x(0), s^2(t) \sigma^2(t)\mathbf{I})\),</p> </li> <li> <p>where \(\mathcal{N}(x; \mu, \Sigma)\)denotes the probability density function of \(\mathcal{N}(\mu, \Sigma)\)evaluated at \(x\),</p> </li> </ul> \[s(t)=\exp \left(\int_0^t f(\xi) \mathrm{d} \xi\right), \quad \text { and } \quad \sigma(t)=\sqrt{\int_0^t \frac{g(\xi)^2}{s(\xi)^2} \mathrm{~d} \xi}\] <ul> <li>The marginal distribution of \(p_t(x)\)is</li> </ul> \[p_t(\boldsymbol{x})=\int_{\mathbb{R}^d} p_{0 t}\left(\boldsymbol{x} \mid \boldsymbol{x}_0\right) p_{\text {data }}\left(\boldsymbol{x}_0\right) \mathrm{d} \boldsymbol{x}_0\] <ul> <li>The probability flow ODE</li> </ul> \[\mathrm{d} \boldsymbol{x}=\left[f(t) \boldsymbol{x}-\frac{1}{2} g(t)^2 \nabla_{\boldsymbol{x}} \log p_t(\boldsymbol{x})\right] \mathrm{d} t .\] <h1 id="understanding-the-diffusion-process">Understanding the diffusion process</h1> <h3 id="idea">Idea</h3> <p>\(f\)and \(g\)are of little practical interest, the marginal distribution are of utmost inportance</p> <h3 id="the-perturbation-kernels-and-marginal-distribution">The perturbation kernels and marginal distribution</h3> \[p_{0 t}(\boldsymbol{x}(t) \mid \boldsymbol{x}(0))=\mathcal{N}\left(\boldsymbol{x}(t) ; s(t) \boldsymbol{x}(0), s(t)^2 \sigma(t)^2 \mathbf{I}\right)\] \[p_t(\boldsymbol{x})=\int_{\mathbb{R}^d} p_{0 t}\left(\boldsymbol{x} \mid \boldsymbol{x}_0\right) p_{\text {data }}\left(\boldsymbol{x}_0\right) \mathrm{d} \boldsymbol{x}_0\] <h3 id="convolution-form">Convolution form</h3> <p>\(p(\boldsymbol{x} ; \sigma) :=p_{\text {data }} * \mathcal{N}(\mathbf{0}, \sigma(t)^2 \mathbf{I})\) \(p_t(\boldsymbol{x})=s(t)^{-d} p(\boldsymbol{x} / s(t) ; \sigma(t))\)</p> <h3 id="ode">ODE</h3> <h4 id="mathrmd-boldsymbolx-dotsigmat-sigmat-nabla_boldsymbolx-log-pboldsymbolx--sigmat-mathrmd-t">\(\mathrm{d} \boldsymbol{x}=-\dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t\)</h4> \[\mathrm{d} \boldsymbol{x}=\left[\frac{\dot{\boldsymbol{s}}(t)}{s(t)} \boldsymbol{x}-s(t)^2 \dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p\left(\frac{\boldsymbol{x}}{s(t)} ; \sigma(t)\right)\right] \mathrm{d} t\] <h3 id="denosing-score-matching">Denosing score matching</h3> <p>\(D(\boldsymbol{x}; \sigma)\)is a denoiser function that minimizes the expeced \(L_2\)denosing error for samples drawn from \(p_{\text{data}}\),</p> <p>\(\mathbb{E}_{\boldsymbol{y} \sim p_{\text {data }}} \mathbb{E}_{\boldsymbol{n} \sim \mathcal{N}\left(\mathbf{0}, \sigma^2 \mathbf{I}\right)}\|D(\boldsymbol{y}+\boldsymbol{n} ; \sigma)-\boldsymbol{y}\|_2^2\), then \(\nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma)=(D(\boldsymbol{x} ; \sigma)-\boldsymbol{x}) / \sigma^2\)</p> <h3 id="heat-equation">Heat equation</h3> <p>$$\left{\begin{matrix}</p> <p>&amp;\frac{\partial q}{\partial t} -\dot{\sigma} \sigma \Delta_{\boldsymbol{x}} q = 0 &amp;\text{in} \quad \mathbb{R}^d \times(0, \, \infty) \ &amp;q= p_{data}(\boldsymbol{x}) &amp; \text{on} \quad \mathbb{R}^d \times {t=0}</p> <p>\end{matrix} \right.$$</p> <h3 id="sde">SDE</h3> <p>\(\mathrm{d} \boldsymbol{x}=\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t+g(t) \mathrm{d} \omega_t\)</p> \[\mathrm{d} \boldsymbol{x}_{ \pm}=\underbrace{-\dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t}_{\text {probability flow ODE}} \pm \underbrace{\beta(t) \sigma(t)^2 \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t}_{\text {deterministic noise decay }}+\underbrace{\sqrt{2 \beta(t)} \sigma(t) \mathrm{d} \omega_t}_{\text {noise injection }}\] <h1 id="ode-formulation">ODE formulation</h1> <h4 id="equation-1-mathrmd-boldsymbolx-dotsigmat-sigmat-nabla_boldsymbolx-log-pboldsymbolx--sigmat-mathrmd-t">Equation 1: \(\mathrm{d} \boldsymbol{x}=-\dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t\)</h4> <h4 id="proof">Proof</h4> <p>The marginal distrobution</p> \[\begin{aligned} p_t(\boldsymbol{x}) &amp; =\int_{\mathbb{R}^d} p_{0 t}\left(\boldsymbol{x} \mid \boldsymbol{x}_0\right) p_{\text {data }}\left(\boldsymbol{x}_0\right) \mathrm{d} \boldsymbol{x}_0 \\ &amp; =\int_{\mathbb{R}^d} p_{\text {data }}\left(\boldsymbol{x}_0\right)\left[\mathcal{N}\left(\boldsymbol{x} ; s(t) \boldsymbol{x}_0, s(t)^2 \sigma(t)^2 \mathbf{I}\right)\right] \mathrm{d} \boldsymbol{x}_0 \\ &amp; =\int_{\mathbb{R}^d} p_{\text {data }}\left(\boldsymbol{x}_0\right)\left[s(t)^{-d} \mathcal{N}\left(\boldsymbol{x} / s(t) ; \boldsymbol{x}_0, \sigma(t)^2 \mathbf{I}\right)\right] \mathrm{d} \boldsymbol{x}_0 \\ &amp; =s(t)^{-d} \int_{\mathbb{R}^d} p_{\text {data }}\left(\boldsymbol{x}_0\right) \mathcal{N}\left(\boldsymbol{x} / s(t) ; \boldsymbol{x}_0, \sigma(t)^2 \mathbf{I}\right) \mathrm{d} \boldsymbol{x}_0 \\ &amp; =s(t)^{-d}\left[p_{\text {data }} * \mathcal{N}\left(\mathbf{0}, \sigma(t)^2 \mathbf{I}\right)\right](\boldsymbol{x} / s(t)), \end{aligned}\] <p>where \(p_a * p_b\)denotes the convolution of probability density functions \(p_a\)and \(p_b\)</p> <p>Let denote:</p> \[p(\boldsymbol{x} ; \sigma)=p_{\text {data }} * \mathcal{N}\left(\mathbf{0}, \sigma(t)^2 \mathbf{I}\right) \quad \text { and } \quad p_t(\boldsymbol{x})=s(t)^{-d} p(\boldsymbol{x} / s(t) ; \sigma(t))\] <p>the probability ﬂow ODE</p> \[\begin{aligned} \mathrm{d} \boldsymbol{x} &amp; =\left[f(t) \boldsymbol{x}-\frac{1}{2} g(t)^2 \nabla_{\boldsymbol{x}} \log \left[p_t(\boldsymbol{x})\right]\right] \mathrm{d} t \\ &amp; =\left[f(t) \boldsymbol{x}-\frac{1}{2} g(t)^2 \nabla_{\boldsymbol{x}} \log \left[s(t)^{-d} p(\boldsymbol{x} / s(t) ; \sigma(t))\right]\right] \mathrm{d} t \\ &amp; =\left[f(t) \boldsymbol{x}-\frac{1}{2} g(t)^2\left[\nabla_{\boldsymbol{x}} \log s(t)^{-d}+\nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} / s(t) ; \sigma(t))\right]\right] \mathrm{d} t \\ &amp; =\left[f(t) \boldsymbol{x}-\frac{1}{2} g(t)^2 \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} / s(t) ; \sigma(t))\right] \mathrm{d} t . \end{aligned}\] <p>Next, \(f(t) = {\dot s(t)}/{s(t)}\), \(g(t) = s(t) \sqrt{2 \dot{\sigma}(t) \sigma(t)}\)</p> \[\begin{aligned} \exp \left(\int_0^t f(\xi) \mathrm{d} \xi\right) &amp; =s(t) \\ \int_0^t f(\xi) \mathrm{d} \xi &amp; =\log s(t) \\ \mathrm{d}\left[\int_0^t f(\xi) \mathrm{d} \xi\right] / \mathrm{d} t &amp; =\mathrm{d}[\log s(t)] / \mathrm{d} t \\ f(t) &amp; =\dot{s}(t) / s(t) . \end{aligned}\] \[\begin{aligned} \sqrt{\int_0^t \frac{g(\xi)^2}{s(\xi)^2} \mathrm{~d} \xi} &amp; =\sigma(t) \\ \int_0^t \frac{g(\xi)^2}{s(\xi)^2} \mathrm{~d} \xi &amp; =\sigma(t)^2 \\ \mathrm{~d}\left[\int_0^t \frac{g(\xi)^2}{s(\xi)^2} \mathrm{~d} \xi\right] / \mathrm{d} t &amp; =\mathrm{d}\left[\sigma(t)^2\right] / \mathrm{d} t \\ g(t)^2 / s(t)^2 &amp; =2 \dot{\sigma}(t) \sigma(t) \\ g(t) / s(t) &amp; =\sqrt{2 \dot{\sigma}(t) \sigma(t)} \\ g(t) &amp; =s(t) \sqrt{2 \dot{\sigma}(t) \sigma(t)} . \end{aligned}\] <p>Finally</p> \[\begin{aligned} \mathrm{d} \boldsymbol{x} &amp; =\left[[f(t)] \boldsymbol{x}-\frac{1}{2}[g(t)]^2 \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} / s(t) ; \sigma(t))\right] \mathrm{d} t \\ &amp; =\left[[\dot{s}(t) / s(t)] \boldsymbol{x}-\frac{1}{2}[s(t) \sqrt{2 \dot{\sigma}(t) \sigma(t)}]^2 \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} / s(t) ; \sigma(t))\right] \mathrm{d} t \\ &amp; =\left[[\dot{s}(t) / s(t)] \boldsymbol{x}-\frac{1}{2}\left[2 s(t)^2 \dot{\sigma}(t) \sigma(t)\right] \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} / s(t) ; \sigma(t))\right] \mathrm{d} t \\ &amp; =\left[\frac{\dot{s}(t)}{s(t)} \boldsymbol{x}-s(t)^2 \dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p\left(\frac{\boldsymbol{x}}{s(t)} ; \sigma(t)\right)\right] \mathrm{d} t \end{aligned}\] <p>By setting \(s(t) = 1\):</p> \[\mathrm{d} \boldsymbol{x}=-\dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t\] <h1 id="denoising-score-matching">Denoising score matching</h1> <h4 id="equation-2--3">Equation 2 &amp; 3</h4> <p>\(\mathbb{E}_{\boldsymbol{y} \sim p_{\text {data }}} \mathbb{E}_{\boldsymbol{n} \sim \mathcal{N}\left(\mathbf{0}, \sigma^2 \mathbf{I}\right)}\|D(\boldsymbol{y}+\boldsymbol{n} ; \sigma)-\boldsymbol{y}\|_2^2\), then \(\nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma)=(D(\boldsymbol{x} ; \sigma)-\boldsymbol{x}) / \sigma^2\)</p> <h4 id="proof-1">Proof</h4> <p>Finite number of samples \(\{\mathbf{y}_1, \cdots, \mathbf{y}_Y \}\),\(p_{data}(x)\)is represented by a mixture of Dirac delta distributions:\(p_{\text{data}}(x) = \frac{1}{Y} \sum_{i=1}^{Y} \delta(\mathbf{x} - \mathbf{y}_i)\)</p> \[\begin{aligned} p(\boldsymbol{x} ; \sigma) &amp; =p_{\text {data }} * \mathcal{N}\left(\mathbf{0}, \sigma(t)^2 \mathbf{I}\right) \\ &amp; =\int_{\mathbb{R}^d} p_{\text {data }}\left(\boldsymbol{x}_0\right) \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{x}_0, \sigma^2 \mathbf{I}\right) \mathrm{d} \boldsymbol{x}_0 \\ &amp; =\int_{\mathbb{R}^d}\left[\frac{1}{Y} \sum_{i=1}^Y \delta\left(\boldsymbol{x}_0-\boldsymbol{y}_i\right)\right] \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{x}_0, \sigma^2 \mathbf{I}\right) \mathrm{d} \boldsymbol{x}_0 \\ &amp; =\frac{1}{Y} \sum_{i=1}^Y \int_{\mathbb{R}^d} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{x}_0, \sigma^2 \mathbf{I}\right) \delta\left(\boldsymbol{x}_0-\boldsymbol{y}_i\right) \mathrm{d} \boldsymbol{x}_0 \\ &amp; =\frac{1}{Y} \sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\end{aligned}\] <p>Considering the Eq. 2. by expanding the expections:</p> \[\begin{aligned} \mathcal{L}(D ; \sigma) &amp; =\mathbb{E}_{\boldsymbol{y} \sim p_{\text {data }}} \mathbb{E}_{\boldsymbol{n} \sim \mathcal{N}\left(\mathbf{0}, \sigma^2 \mathbf{I}\right)}\|D(\boldsymbol{y}+\boldsymbol{n} ; \sigma)-\boldsymbol{y}\|_2^2 \\ &amp; =\mathbb{E}_{\boldsymbol{y} \sim p_{\text {data }}} \mathbb{E}_{\boldsymbol{x} \sim \mathcal{N}\left(\boldsymbol{y}, \sigma^2 \mathbf{I}\right)}\|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}\|_2^2 \\ &amp; =\mathbb{E}_{\boldsymbol{y} \sim p_{\text {data }}} \int_{\mathbb{R}^d} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}, \sigma^2 \mathbf{I}\right)\|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}\|_2^2 \mathrm{~d} \boldsymbol{x} \\ &amp; =\frac{1}{Y} \sum_{i=1}^Y \int_{\mathbb{R}^d} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\left\|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}_i\right\|_2^2 \mathrm{~d} \boldsymbol{x} \\ &amp; =\int_{\mathbb{R}^d} \underbrace{\frac{1}{Y} \sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\left\|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}_i\right\|_2^2}_{=: \mathcal{L}(D ; \boldsymbol{x}, \sigma)} \mathrm{d} \boldsymbol{x} .\end{aligned}\] <p>we can minimize \(\mathcal{L}(D ; \sigma)\)by minimizing $$\mathcal{L}(D ; \boldsymbol{x}, \sigma)</p> <p>\(independently for each\)\boldsymbol{x}$$:</p> <p>\(D(\boldsymbol{x} ; \sigma)=\arg \min _{D(\boldsymbol{x} ; \sigma)} \mathcal{L}(D ; \boldsymbol{x}, \sigma)\) This is a convex optimization problem; its solution is uniquely identiﬁed by setting the gradient w.r.t. \(D(\boldsymbol{x}; \sigma)\)to zero:</p> \[\begin{aligned} \mathbf{0} &amp; =\nabla_{D(\boldsymbol{x} ; \sigma)}[\mathcal{L}(D ; \boldsymbol{x}, \sigma)] \\ \mathbf{0} &amp; =\nabla_{D(\boldsymbol{x} ; \sigma)}\left[\frac{1}{Y} \sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\left\|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}_i\right\|_2^2\right] \\ \mathbf{0} &amp; =\sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \nabla_{D(\boldsymbol{x} ; \sigma)}\left[\left\|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}_i\right\|_2^2\right] \\ \mathbf{0} &amp; =\sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\left[2 D(\boldsymbol{x} ; \sigma)-2 \boldsymbol{y}_i\right] \\ \mathbf{0} &amp; =\left[\sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\right] D(\boldsymbol{x} ; \sigma)-\sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \boldsymbol{y}_i \\ D(\boldsymbol{x} ; \sigma) &amp; =\frac{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \boldsymbol{y}_i}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}\end{aligned}\] <p>which gives a closed-form solution for the ideal denoiser \(D(\boldsymbol{x}; \sigma)\).</p> \[D(\boldsymbol{x} ; \sigma) =\frac{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \boldsymbol{y}_i}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}\] <p>Next, let us consider the score of the distribution</p> \[\begin{aligned} \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma) &amp; =\frac{\nabla_{\boldsymbol{x}} p(\boldsymbol{x} ; \sigma)}{p(\boldsymbol{x} ; \sigma)} \\ &amp; =\frac{\nabla_{\boldsymbol{x}}\left[\frac{1}{Y} \sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\right]}{\left[\frac{1}{Y} \sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\right]} \\ &amp; =\frac{\sum_i \nabla_{\boldsymbol{x}} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}\end{aligned}\] <p>Then</p> \[\begin{aligned} \nabla_{\boldsymbol{x}} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) &amp; =\nabla_{\boldsymbol{x}}\left[\left(2 \pi \sigma^2\right)^{-\frac{d}{2}} \exp \frac{\left\|\boldsymbol{x}-\boldsymbol{y}_i\right\|_2^2}{-2 \sigma^2}\right] \\ &amp; =\left(2 \pi \sigma^2\right)^{-\frac{d}{2}} \nabla_{\boldsymbol{x}}\left[\exp \frac{\left\|\boldsymbol{x}-\boldsymbol{y}_i\right\|_2^2}{-2 \sigma^2}\right] \\ &amp; =\left[\left(2 \pi \sigma^2\right)^{-\frac{d}{2}} \exp \frac{\left\|\boldsymbol{x}-\boldsymbol{y}_i\right\|_2^2}{-2 \sigma^2}\right] \nabla_{\boldsymbol{x}}\left[\frac{\left\|\boldsymbol{x}-\boldsymbol{y}_i\right\|_2^2}{-2 \sigma^2}\right] \\ &amp; =\mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \nabla_{\boldsymbol{x}}\left[\frac{\left\|\boldsymbol{x}-\boldsymbol{y}_i\right\|_2^2}{-2 \sigma^2}\right] \\ &amp; =\mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\left[\frac{\boldsymbol{y}_i-\boldsymbol{x}}{\sigma^2}\right] .\end{aligned}\] <p>Next</p> \[\begin{aligned} \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma) &amp; =\frac{\sum_i \nabla_{\boldsymbol{x}} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)} \\ &amp; =\frac{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\left[\frac{\boldsymbol{y}_i-\boldsymbol{x}}{\sigma^2}\right]}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)} \\ &amp; =\left(\frac{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \boldsymbol{y}_i}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}-\boldsymbol{x}\right) / \sigma^2 .\end{aligned}\] <p>So \(\nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma)=(D(\boldsymbol{x} ; \sigma)-\boldsymbol{x}) / \sigma^2\)</p> <h1 id="proposed-sde">Proposed SDE</h1> <h3 id="task-1-find-a-pde-given-initial-value-qboldsymbolx-0-p_databoldsymbolx-and-solution-qboldsymbolx-t--pboldsymbolx-sigmat">Task 1: Find a PDE given initial value \(q(\boldsymbol{x}, 0):= p_{data}(\boldsymbol{x})\), and solution \(q(\boldsymbol{x}, t) = p(\boldsymbol{x}, \sigma(t))\)</h3> <h4 id="the-solution-is-a-heat-equation">The solution is a heat equation</h4> \[\frac{\partial q(\boldsymbol{x}, t)}{\partial t}=\dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)\] <h4 id="proof-2">Proof</h4> <p>\(p(\boldsymbol{x} ; \sigma)=p_{\text {data }} * \mathcal{N}\left(\mathbf{0}, \sigma(t)^2 \mathbf{I}\right)\) and \(p_t(\boldsymbol{x})=s(t)^{-d} p(\boldsymbol{x} / s(t) ; \sigma(t))\)</p> <p>the density evolves according to a heat diffusion PDE with time-varying diffusivity. As a ﬁrst step, we ﬁnd this PDE.</p> <p>The solution can be generated by the heat equation with time-varying diffusivity \(\kappa(t)\).</p> <p>The heat equation PDE:</p> \[\frac{\partial \hat{q}(\boldsymbol{\nu}, t)}{\partial t}=-\kappa(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t)\] <p>Take Fourier transform along the \(\boldsymbol{x}-\text{dimension}\)</p> \[\frac{\partial \hat{q}(\boldsymbol{\nu}, t)}{\partial t}=-\kappa(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t)\] <p>Since \(q(\boldsymbol{x}, t)=p(\boldsymbol{x} ; \sigma(t))=p_{\text {data }}(\boldsymbol{x}) * \mathcal{N}\left(\mathbf{0}, \sigma(t)^2 \mathbf{I}\right)\), \(\hat{q}(\boldsymbol{\nu}, t)=\hat{p}_{\text {data }}(\boldsymbol{\nu}) \exp \left(-\frac{1}{2}|\boldsymbol{\nu}|^2 \sigma(t)^2\right)\)</p> <p>Differentiating the target solution along the time axis, we have</p> <p>\(\begin{aligned} \frac{\partial \hat{q}(\boldsymbol{\nu}, t)}{\partial t} &amp; =-\dot{\sigma}(t) \sigma(t)|\boldsymbol{\nu}|^2 \hat{p}_{\text {data }}(\boldsymbol{\nu}) \exp \left(-\frac{1}{2}|\boldsymbol{\nu}|^2 \sigma(t)^2\right) \\ &amp; =-\dot{\sigma}(t) \sigma(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t)\end{aligned}\) Then we have</p> \[\begin{aligned}-\kappa(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t) &amp; =-\dot{\sigma}(t) \sigma(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t) \\ \kappa(t) &amp; =\dot{\sigma}(t) \sigma(t) .\end{aligned}\] <p>To summzrize</p> \[\frac{\partial q(\boldsymbol{x}, t)}{\partial t}=\dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)\] <h3 id="task-2-seek-an-sde-whose-solution-density-is-described-by-the-pde-fracpartial-qboldsymbolx-tpartial-tdotsigmat-sigmat-delta_boldsymbolx-qboldsymbolx-t">Task 2: Seek an SDE whose solution density is described by the PDE \(\frac{\partial q(\boldsymbol{x}, t)}{\partial t}=\dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)\)</h3> <h4 id="solution-mathrmd-boldsymbolxleftfrac12-gt2-dotsigmat-sigmatright-nabla_boldsymbolx-log-pboldsymbolx--sigmat-mathrmd-tgt-mathrmd-omega_t">Solution: \(\mathrm{d} \boldsymbol{x}=\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t+g(t) \mathrm{d} \omega_t\)</h4> <h4 id="proof-3">Proof</h4> <p>Given an SDE,\(\mathrm{d} \boldsymbol{x}=\boldsymbol{f}(\boldsymbol{x}, t) \mathrm{d} t+\boldsymbol{g}(\boldsymbol{x}, t) \mathrm{d} \omega_t\), The Fokker–Planck PDE describes the time evolution of its solution probability density \(r(\boldsymbol{x},t)\) as</p> \[\frac{\partial r(\boldsymbol{x}, t)}{\partial t}=-\nabla_{\boldsymbol{x}} \cdot(\boldsymbol{f}(\boldsymbol{x}, t) r(\boldsymbol{x}, t))+\frac{1}{2} \nabla_{\boldsymbol{x}} \nabla_{\boldsymbol{x}}:(\mathbf{D}(\boldsymbol{x}, t) r(\boldsymbol{x}, t))\] <p>where \(\mathbf{D}_{i j}=\sum_k \boldsymbol{g}_{i k} \boldsymbol{g}_{j k}\) is diffusion tensor. We consider a special case \(\boldsymbol{g}(\boldsymbol{x}, t) = g(t) \boldsymbol{I}\)</p> \[\frac{\partial r(\boldsymbol{x}, t)}{\partial t}=-\nabla_{\boldsymbol{x}} \cdot(\boldsymbol{f}(\boldsymbol{x}, t) r(\boldsymbol{x}, t))+\frac{1}{2} g(t)^2 \Delta_{\boldsymbol{x}} r(\boldsymbol{x}, t)\] <p>We can find a sufﬁcient condition that sastify the PDE \(\frac{\partial q(\boldsymbol{x}, t)}{\partial t}=\dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)\)</p> \[-\nabla_{\boldsymbol{x}} \cdot(\boldsymbol{f}(\boldsymbol{x}, t) q(\boldsymbol{x}, t))+\frac{1}{2} g(t)^2 \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t) = \dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)\] <p>The key is given by the identity \(\nabla_{\boldsymbol{x}} \cdot \nabla_{\boldsymbol{x}}=\Delta_{\boldsymbol{x}}\). We set \(\boldsymbol{f}(\boldsymbol{x}, t) q(\boldsymbol{x}, t)=v(t) \nabla_{\boldsymbol{x}} q(\boldsymbol{x}, t)\), then</p> \[\begin{aligned} \nabla_{\boldsymbol{x}} \cdot\left(v(t) \nabla_{\boldsymbol{x}} q(\boldsymbol{x}, t)\right) &amp; =\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t) \\ v(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t) &amp; =\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t) \\ v(t) &amp; =\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t) .\end{aligned}\] <p>\(\boldsymbol{f}(\boldsymbol{x}, t)\)is in fact proportional to the score function:</p> \[\begin{aligned} \boldsymbol{f}(\boldsymbol{x}, t) &amp; =v(t) \frac{\nabla_{\boldsymbol{x}} q(\boldsymbol{x}, t)}{q(\boldsymbol{x}, t)} \\ &amp; =v(t) \nabla_{\boldsymbol{x}} \log q(\boldsymbol{x}, t) \\ &amp; =\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \nabla_{\boldsymbol{x}} \log q(\boldsymbol{x}, t)\end{aligned}\] <p>we recover a family of SDEs whose solution densities have the desired marginals with noise levels \(\sigma(t)\) for any choice of \(g(t)\):</p> \[\mathrm{d} \boldsymbol{x}=\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t+g(t) \mathrm{d} \omega_t\] </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Consistency-model/">Consistency models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/SGM-(NCSN)/">Generative Modeling by Estimating Gradients of the Data Distribution</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Reverse-time-Diffusion-Equation-Models/">Reverse time diffusion equation models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Wasserstein-Lagrangian-Flows/">A Computational Framework For Solving Wassertein Lagrangian Flows</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/CLD/">Score-based generative modeling with critically-damped Langevin diffusion</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Shaorong R. Zhang. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.getElementById("WeChatBtn");wechatBtn.onclick=function(){wechatModal.style.display="block"},window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> </body> </html>