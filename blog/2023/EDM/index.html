<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="original-ode--sde-formulation-from-previous-work">Original ODE / SDE formulation from previous work</h1> <ul> <li>Song et al. define their forward SDE as: $dx = f(x,t)dt + g(t) dw_t$, where $f(\cdot, t):\mathbb{R}^d \rightarrow \mathbb{R}^d$and $g(\cdot): \mathbb{R} \rightarrow \mathbb{R}$are the drift and diffusion coefficients, repsectively, where $d$is the dimensionality of the dataset. $f(\cdot)$is always of the form $f(x, t) = f(t) x$, where $f(\cdot):\mathbb{R} \rightarrow \mathbb{R}$.</li> <li>Thus, the SDE can be equivalently written as$dx = f(t)x + g(t) d w_t$.</li> <li> <table> <tbody> <tr> <td>The pertubation kernels of this SDE have the general form $p_{0t}(x(t)</td> <td>x(0)) = \mathcal{N} (x(t); s(t)x(0), s^2(t) \sigma^2(t)\mathbf{I})$,</td> </tr> </tbody> </table> </li> <li>where $\mathcal{N}(x; \mu, \Sigma)$denotes the probability density function of $\mathcal{N}(\mu, \Sigma)$evaluated at $x$,</li> </ul> <p><img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697930172374-2c15fd2a-68e7-47ad-8167-3b372e6cc27a.png#averageHue=%23f5f5f5&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=70&amp;id=u4fa8c5c6&amp;originHeight=140&amp;originWidth=853&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=25020&amp;status=done&amp;style=none&amp;taskId=ua55e5685-8108-45a8-80fc-7c2438ea088&amp;title=&amp;width=426.5" alt="image.png"></p> <ul> <li>The marginal distribution of $p_t(x)$is</li> </ul> <p><img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697930257381-db952a3d-05e4-4996-9006-4d07fa59a526.png#averageHue=%23f1f1f1&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=43&amp;id=u4421d568&amp;originHeight=85&amp;originWidth=536&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=13425&amp;status=done&amp;style=none&amp;taskId=u24e7dd04-d765-402f-8eba-3133d0dcb50&amp;title=&amp;width=268" alt="image.png"></p> <ul> <li>The probability flow ODE</li> </ul> <p><img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697930289525-9c84f26a-65e1-4569-88ec-c4a12499f5ff.png#averageHue=%23ececec&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=34&amp;id=u0ee0774b&amp;originHeight=61&amp;originWidth=559&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=13896&amp;status=done&amp;style=none&amp;taskId=udf9fe673-3e69-48f0-b8e8-beb67581336&amp;title=&amp;width=310.5" alt="image.png"></p> <h1 id="understanding-the-diffusion-process">Understanding the diffusion process</h1> <h3 id="idea">Idea</h3> <p>$f$and $g$are of little practical interest, the marginal distribution are of utmost inportance</p> <h3 id="the-perturbation-kernels-and-marginal-distribution">The perturbation kernels and marginal distribution</h3> <p>$p_{0 t}(\boldsymbol{x}(t) \mid \boldsymbol{x}(0))=\mathcal{N}\left(\boldsymbol{x}(t) ; s(t) \boldsymbol{x}(0), s(t)^2 \sigma(t)^2 \mathbf{I}\right)$ $p_t(\boldsymbol{x})=\int_{\mathbb{R}^d} p_{0 t}\left(\boldsymbol{x} \mid \boldsymbol{x}<em>0\right) p</em>{\text {data }}\left(\boldsymbol{x}_0\right) \mathrm{d} \boldsymbol{x}_0$</p> <h3 id="convolution-form">Convolution form</h3> <p>$p(\boldsymbol{x} ; \sigma) :=p_{\text {data }} * \mathcal{N}(\mathbf{0}, \sigma(t)^2 \mathbf{I})$ $p_t(\boldsymbol{x})=s(t)^{-d} p(\boldsymbol{x} / s(t) ; \sigma(t))$</p> <h3 id="ode">ODE</h3> <h4 id="mathrmd-boldsymbolx-dotsigmat-sigmat-nabla_boldsymbolx-log-pboldsymbolx--sigmat-mathrmd-t">$\mathrm{d} \boldsymbol{x}=-\dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t$</h4> <p>$\mathrm{d} \boldsymbol{x}=\left[\frac{\dot{\boldsymbol{s}}(t)}{s(t)} \boldsymbol{x}-s(t)^2 \dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p\left(\frac{\boldsymbol{x}}{s(t)} ; \sigma(t)\right)\right] \mathrm{d} t$</p> <h3 id="denosing-score-matching">Denosing score matching</h3> <p>$D(\boldsymbol{x}; \sigma)$is a denoiser function that minimizes the expeced $L_2$denosing error for samples drawn from $p_{\text{data}}$, $\mathbb{E}<em>{\boldsymbol{y} \sim p</em>{\text {data }}} \mathbb{E}<em>{\boldsymbol{n} \sim \mathcal{N}\left(\mathbf{0}, \sigma^2 \mathbf{I}\right)}|D(\boldsymbol{y}+\boldsymbol{n} ; \sigma)-\boldsymbol{y}|_2^2$, then $\nabla</em>{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma)=(D(\boldsymbol{x} ; \sigma)-\boldsymbol{x}) / \sigma^2$</p> <h3 id="heat-equation">Heat equation</h3> <p>$\left{\begin{matrix}</p> <p>&amp;\frac{\partial q}{\partial t} -\dot{\sigma} \sigma \Delta_{\boldsymbol{x}} q = 0 &amp;\text{in} \quad \mathbb{R}^d \times(0, \, \infty) \ &amp;q= p_{data}(\boldsymbol{x}) &amp; \text{on} \quad \mathbb{R}^d \times {t=0}</p> <p>\end{matrix} \right.$</p> <h3 id="sde">SDE</h3> <p>$\mathrm{d} \boldsymbol{x}=\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t+g(t) \mathrm{d} \omega_t$ $\mathrm{d} \boldsymbol{x}<em>{ \pm}=\underbrace{-\dot{\sigma}(t) \sigma(t) \nabla</em>{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t}<em>{\text {probability flow ODE}} \pm \underbrace{\beta(t) \sigma(t)^2 \nabla</em>{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t}<em>{\text {deterministic noise decay }}+\underbrace{\sqrt{2 \beta(t)} \sigma(t) \mathrm{d} \omega_t}</em>{\text {noise injection }}$</p> <h1 id="ode-formulation">ODE formulation</h1> <h4 id="equation-1-mathrmd-boldsymbolx-dotsigmat-sigmat-nabla_boldsymbolx-log-pboldsymbolx--sigmat-mathrmd-t">Equation 1: $\mathrm{d} \boldsymbol{x}=-\dot{\sigma}(t) \sigma(t) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t$</h4> <h4 id="proof">Proof</h4> <p>The marginal distrobution <img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697930569096-d5a257f3-6450-484f-afd6-041f31e6a10f.png#averageHue=%23f5f5f5&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=206&amp;id=u638b3b63&amp;originHeight=411&amp;originWidth=1089&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=79908&amp;status=done&amp;style=none&amp;taskId=u313df4ce-60f6-4073-8c19-a436b95fc7c&amp;title=&amp;width=544.5" alt="image.png"> where $p_a * p_b$denotes the convolution of probability density functions $p_a$and $p_b$ Let denote: <img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697930701606-9f6d0ebd-be76-4eb4-bbbf-d53b65041430.png#averageHue=%23ededed&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=30&amp;id=u983cd5f5&amp;originHeight=59&amp;originWidth=969&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=18831&amp;status=done&amp;style=none&amp;taskId=ub805e725-d7ff-48bc-85fb-06c5e181f8f&amp;title=&amp;width=484.5" alt="image.png"> the probability ﬂow ODE <img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697930831219-82ef998f-97eb-494c-bd79-a4bd260357a6.png#averageHue=%23f0f0f0&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=106&amp;id=uad3225bf&amp;originHeight=211&amp;originWidth=1159&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=62671&amp;status=done&amp;style=none&amp;taskId=u1dd8658d-ccec-4ad9-90a4-88582f1b435&amp;title=&amp;width=579.5" alt="image.png"> Next, $f(t) = {\dot s(t)}/{s(t)}$, $g(t) = s(t) \sqrt{2 \dot{\sigma}(t) \sigma(t)}$ <img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697930954904-0a5b9b1a-97f1-4647-a688-d820c439d120.png#averageHue=%23f8f8f8&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=170&amp;id=u75a1a75b&amp;originHeight=340&amp;originWidth=964&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=50358&amp;status=done&amp;style=none&amp;taskId=u69cf4036-dd99-4d84-8263-067f88ba2a0&amp;title=&amp;width=482" alt="image.png"> <img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697931014823-264dcafd-b5a4-4d78-8a1f-4edea0ec0779.png#averageHue=%23f7f7f7&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=227&amp;id=u5e5bb92b&amp;originHeight=453&amp;originWidth=980&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=77385&amp;status=done&amp;style=none&amp;taskId=u22ea01df-7d17-4abf-a48c-4743f3c12f9&amp;title=&amp;width=490" alt="image.png"> Finally <img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697931039779-bb7dc83a-0142-42e3-a26e-0110a91f4103.png#averageHue=%23f3f3f3&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=175&amp;id=udfc3e8bb&amp;originHeight=349&amp;originWidth=1012&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=69591&amp;status=done&amp;style=none&amp;taskId=u8d189c60-063b-400a-b206-37fbf84b84a&amp;title=&amp;width=506" alt="image.png"> By setting $s(t) = 1$: <img src="https://cdn.nlark.com/yuque/0/2023/png/27584564/1697931108682-eb182f7a-83c3-4c1e-853b-0b5f5d11b881.png#averageHue=%23ececec&amp;clientId=u312744c2-edfb-4&amp;from=paste&amp;height=32&amp;id=u87895a30&amp;originHeight=60&amp;originWidth=514&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=13035&amp;status=done&amp;style=none&amp;taskId=u9227af1f-b801-4cdf-9ef4-91404a710b6&amp;title=&amp;width=275" alt="image.png"></p> <h1 id="denoising-score-matching">Denoising score matching</h1> <h4 id="equation-2--3">Equation 2 &amp; 3</h4> <p>$\mathbb{E}<em>{\boldsymbol{y} \sim p</em>{\text {data }}} \mathbb{E}<em>{\boldsymbol{n} \sim \mathcal{N}\left(\mathbf{0}, \sigma^2 \mathbf{I}\right)}|D(\boldsymbol{y}+\boldsymbol{n} ; \sigma)-\boldsymbol{y}|_2^2$, then $\nabla</em>{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma)=(D(\boldsymbol{x} ; \sigma)-\boldsymbol{x}) / \sigma^2$</p> <h4 id="proof-1">Proof</h4> <p>Finite number of samples ${\mathbf{y}<em>1, \cdots, \mathbf{y}_Y }$,$p</em>{data}(x)$is represented by a mixture of Dirac delta distributions:$p_{\text{data}}(x) = \frac{1}{Y} \sum_{i=1}^{Y} \delta(\mathbf{x} - \mathbf{y}<em>i)$ $\begin{aligned} p(\boldsymbol{x} ; \sigma) &amp; =p</em>{\text {data }} * \mathcal{N}\left(\mathbf{0}, \sigma(t)^2 \mathbf{I}\right) \ &amp; =\int_{\mathbb{R}^d} p_{\text {data }}\left(\boldsymbol{x}<em>0\right) \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{x}_0, \sigma^2 \mathbf{I}\right) \mathrm{d} \boldsymbol{x}_0 \ &amp; =\int</em>{\mathbb{R}^d}\left[\frac{1}{Y} \sum_{i=1}^Y \delta\left(\boldsymbol{x}<em>0-\boldsymbol{y}_i\right)\right] \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{x}_0, \sigma^2 \mathbf{I}\right) \mathrm{d} \boldsymbol{x}_0 \ &amp; =\frac{1}{Y} \sum</em>{i=1}^Y \int_{\mathbb{R}^d} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{x}<em>0, \sigma^2 \mathbf{I}\right) \delta\left(\boldsymbol{x}_0-\boldsymbol{y}_i\right) \mathrm{d} \boldsymbol{x}_0 \ &amp; =\frac{1}{Y} \sum</em>{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)\end{aligned}$<br> Considering the Eq. 2. by expanding the expections: $\begin{aligned} \mathcal{L}(D ; \sigma) &amp; =\mathbb{E}</em>{\boldsymbol{y} \sim p_{\text {data }}} \mathbb{E}<em>{\boldsymbol{n} \sim \mathcal{N}\left(\mathbf{0}, \sigma^2 \mathbf{I}\right)}|D(\boldsymbol{y}+\boldsymbol{n} ; \sigma)-\boldsymbol{y}|_2^2 \ &amp; =\mathbb{E}</em>{\boldsymbol{y} \sim p_{\text {data }}} \mathbb{E}<em>{\boldsymbol{x} \sim \mathcal{N}\left(\boldsymbol{y}, \sigma^2 \mathbf{I}\right)}|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}|_2^2 \ &amp; =\mathbb{E}</em>{\boldsymbol{y} \sim p_{\text {data }}} \int_{\mathbb{R}^d} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}, \sigma^2 \mathbf{I}\right)|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}|<em>2^2 \mathrm{~d} \boldsymbol{x} \ &amp; =\frac{1}{Y} \sum</em>{i=1}^Y \int_{\mathbb{R}^d} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)\left|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}_i\right|_2^2 \mathrm{~d} \boldsymbol{x} \ &amp; =\int</em>{\mathbb{R}^d} \underbrace{\frac{1}{Y} \sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)\left|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}_i\right|_2^2}</em>{=: \mathcal{L}(D ; \boldsymbol{x}, \sigma)} \mathrm{d} \boldsymbol{x} .\end{aligned}$ we can minimize $\mathcal{L}(D ; \sigma)$by minimizing $\mathcal{L}(D ; \boldsymbol{x}, \sigma)$independently for each $\boldsymbol{x}$: $D(\boldsymbol{x} ; \sigma)=\arg \min <em>{D(\boldsymbol{x} ; \sigma)} \mathcal{L}(D ; \boldsymbol{x}, \sigma)$ This is a convex optimization problem; its solution is uniquely identiﬁed by setting the gradient w.r.t. $D(\boldsymbol{x}; \sigma)$to zero: $\begin{aligned} \mathbf{0} &amp; =\nabla</em>{D(\boldsymbol{x} ; \sigma)}[\mathcal{L}(D ; \boldsymbol{x}, \sigma)] \ \mathbf{0} &amp; =\nabla_{D(\boldsymbol{x} ; \sigma)}\left[\frac{1}{Y} \sum_{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)\left|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}_i\right|_2^2\right] \ \mathbf{0} &amp; =\sum</em>{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right) \nabla</em>{D(\boldsymbol{x} ; \sigma)}\left[\left|D(\boldsymbol{x} ; \sigma)-\boldsymbol{y}<em>i\right|_2^2\right] \ \mathbf{0} &amp; =\sum</em>{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)\left[2 D(\boldsymbol{x} ; \sigma)-2 \boldsymbol{y}_i\right] \ \mathbf{0} &amp; =\left[\sum</em>{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)\right] D(\boldsymbol{x} ; \sigma)-\sum</em>{i=1}^Y \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right) \boldsymbol{y}_i \ D(\boldsymbol{x} ; \sigma) &amp; =\frac{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \boldsymbol{y}_i}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}\end{aligned}$ which gives a closed-form solution for the ideal denoiser $D(\boldsymbol{x}; \sigma)$. $D(\boldsymbol{x} ; \sigma) =\frac{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \boldsymbol{y}_i}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}$ Next, let us consider the score of the distribution $\begin{aligned} \nabla</em>{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma) &amp; =\frac{\nabla_{\boldsymbol{x}} p(\boldsymbol{x} ; \sigma)}{p(\boldsymbol{x} ; \sigma)} \ &amp; =\frac{\nabla_{\boldsymbol{x}}\left[\frac{1}{Y} \sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)\right]}{\left[\frac{1}{Y} \sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\right]} \ &amp; =\frac{\sum_i \nabla</em>{\boldsymbol{x}} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}\end{aligned}$ Then $\begin{aligned} \nabla</em>{\boldsymbol{x}} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right) &amp; =\nabla</em>{\boldsymbol{x}}\left[\left(2 \pi \sigma^2\right)^{-\frac{d}{2}} \exp \frac{\left|\boldsymbol{x}-\boldsymbol{y}<em>i\right|_2^2}{-2 \sigma^2}\right] \ &amp; =\left(2 \pi \sigma^2\right)^{-\frac{d}{2}} \nabla</em>{\boldsymbol{x}}\left[\exp \frac{\left|\boldsymbol{x}-\boldsymbol{y}<em>i\right|_2^2}{-2 \sigma^2}\right] \ &amp; =\left[\left(2 \pi \sigma^2\right)^{-\frac{d}{2}} \exp \frac{\left|\boldsymbol{x}-\boldsymbol{y}_i\right|_2^2}{-2 \sigma^2}\right] \nabla</em>{\boldsymbol{x}}\left[\frac{\left|\boldsymbol{x}-\boldsymbol{y}<em>i\right|_2^2}{-2 \sigma^2}\right] \ &amp; =\mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \nabla</em>{\boldsymbol{x}}\left[\frac{\left|\boldsymbol{x}-\boldsymbol{y}<em>i\right|_2^2}{-2 \sigma^2}\right] \ &amp; =\mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\left[\frac{\boldsymbol{y}_i-\boldsymbol{x}}{\sigma^2}\right] .\end{aligned}$ Next $\begin{aligned} \nabla</em>{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma) &amp; =\frac{\sum_i \nabla_{\boldsymbol{x}} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}<em>i, \sigma^2 \mathbf{I}\right)}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)} \ &amp; =\frac{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)\left[\frac{\boldsymbol{y}_i-\boldsymbol{x}}{\sigma^2}\right]}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)} \ &amp; =\left(\frac{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right) \boldsymbol{y}_i}{\sum_i \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{y}_i, \sigma^2 \mathbf{I}\right)}-\boldsymbol{x}\right) / \sigma^2 .\end{aligned}$ So $\nabla</em>{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma)=(D(\boldsymbol{x} ; \sigma)-\boldsymbol{x}) / \sigma^2$</p> <h1 id="proposed-sde">Proposed SDE</h1> <h3 id="task-1-find-a-pde-given-initial-value-qboldsymbolx-0-p_databoldsymbolx-and-solution-qboldsymbolx-t--pboldsymbolx-sigmat">Task 1: Find a PDE given initial value $q(\boldsymbol{x}, 0):= p_{data}(\boldsymbol{x})$, and solution $q(\boldsymbol{x}, t) = p(\boldsymbol{x}, \sigma(t))$</h3> <h4 id="the-solution-is-a-heat-equation">The solution is a heat equation</h4> <p>$\frac{\partial q(\boldsymbol{x}, t)}{\partial t}=\dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)$</p> <h4 id="proof-2">Proof</h4> <p>$p(\boldsymbol{x} ; \sigma)=p_{\text {data }} * \mathcal{N}\left(\mathbf{0}, \sigma(t)^2 \mathbf{I}\right)$ and $p_t(\boldsymbol{x})=s(t)^{-d} p(\boldsymbol{x} / s(t) ; \sigma(t))$ the density evolves according to a heat diffusion PDE with time-varying diffusivity. As a ﬁrst step, we ﬁnd this PDE. The solution can be generated by the heat equation with time-varying diffusivity $\kappa(t)$. The heat equation PDE: $\frac{\partial \hat{q}(\boldsymbol{\nu}, t)}{\partial t}=-\kappa(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t)$ Take Fourier transform along the $\boldsymbol{x}-\text{dimension}$ $\frac{\partial \hat{q}(\boldsymbol{\nu}, t)}{\partial t}=-\kappa(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t)$ Since $q(\boldsymbol{x}, t)=p(\boldsymbol{x} ; \sigma(t))=p_{\text {data }}(\boldsymbol{x}) * \mathcal{N}\left(\mathbf{0}, \sigma(t)^2 \mathbf{I}\right)$, $\hat{q}(\boldsymbol{\nu}, t)=\hat{p}<em>{\text {data }}(\boldsymbol{\nu}) \exp \left(-\frac{1}{2}|\boldsymbol{\nu}|^2 \sigma(t)^2\right)$ Differentiating the target solution along the time axis, we have $\begin{aligned} \frac{\partial \hat{q}(\boldsymbol{\nu}, t)}{\partial t} &amp; =-\dot{\sigma}(t) \sigma(t)|\boldsymbol{\nu}|^2 \hat{p}</em>{\text {data }}(\boldsymbol{\nu}) \exp \left(-\frac{1}{2}|\boldsymbol{\nu}|^2 \sigma(t)^2\right) \ &amp; =-\dot{\sigma}(t) \sigma(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t)\end{aligned}$ Then we have $\begin{aligned}-\kappa(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t) &amp; =-\dot{\sigma}(t) \sigma(t)|\boldsymbol{\nu}|^2 \hat{q}(\boldsymbol{\nu}, t) \ \kappa(t) &amp; =\dot{\sigma}(t) \sigma(t) .\end{aligned}$ To summzrize $\frac{\partial q(\boldsymbol{x}, t)}{\partial t}=\dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)$</p> <h3 id="task-2-seek-an-sde-whose-solution-density-is-described-by-the-pde-fracpartial-qboldsymbolx-tpartial-tdotsigmat-sigmat-delta_boldsymbolx-qboldsymbolx-t">Task 2: Seek an SDE whose solution density is described by the PDE $\frac{\partial q(\boldsymbol{x}, t)}{\partial t}=\dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)$</h3> <h4 id="solution-mathrmd-boldsymbolxleftfrac12-gt2-dotsigmat-sigmatright-nabla_boldsymbolx-log-pboldsymbolx--sigmat-mathrmd-tgt-mathrmd-omega_t">Solution: $\mathrm{d} \boldsymbol{x}=\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t+g(t) \mathrm{d} \omega_t$</h4> <h4 id="proof-3">Proof</h4> <p>Given an SDE,$\mathrm{d} \boldsymbol{x}=\boldsymbol{f}(\boldsymbol{x}, t) \mathrm{d} t+\boldsymbol{g}(\boldsymbol{x}, t) \mathrm{d} \omega_t$, The Fokker–Planck PDE describes the time evolution of its solution probability density $r(\boldsymbol{x},t)$as $\frac{\partial r(\boldsymbol{x}, t)}{\partial t}=-\nabla_{\boldsymbol{x}} \cdot(\boldsymbol{f}(\boldsymbol{x}, t) r(\boldsymbol{x}, t))+\frac{1}{2} \nabla_{\boldsymbol{x}} \nabla_{\boldsymbol{x}}:(\mathbf{D}(\boldsymbol{x}, t) r(\boldsymbol{x}, t))$ where $\mathbf{D}<em>{i j}=\sum_k \boldsymbol{g}</em>{i k} \boldsymbol{g}<em>{j k}$is diffusion tensor. We consider a special case $\boldsymbol{g}(\boldsymbol{x}, t) = g(t) \boldsymbol{I}$ $\frac{\partial r(\boldsymbol{x}, t)}{\partial t}=-\nabla</em>{\boldsymbol{x}} \cdot(\boldsymbol{f}(\boldsymbol{x}, t) r(\boldsymbol{x}, t))+\frac{1}{2} g(t)^2 \Delta_{\boldsymbol{x}} r(\boldsymbol{x}, t)$ We can find a sufﬁcient condition that sastify the PDE $\frac{\partial q(\boldsymbol{x}, t)}{\partial t}=\dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)$ $-\nabla_{\boldsymbol{x}} \cdot(\boldsymbol{f}(\boldsymbol{x}, t) q(\boldsymbol{x}, t))+\frac{1}{2} g(t)^2 \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t) = \dot{\sigma}(t) \sigma(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t)$ The key is given by the identity $\nabla_{\boldsymbol{x}} \cdot \nabla_{\boldsymbol{x}}=\Delta_{\boldsymbol{x}}$. We set $\boldsymbol{f}(\boldsymbol{x}, t) q(\boldsymbol{x}, t)=v(t) \nabla_{\boldsymbol{x}} q(\boldsymbol{x}, t)$, then $\begin{aligned} \nabla_{\boldsymbol{x}} \cdot\left(v(t) \nabla_{\boldsymbol{x}} q(\boldsymbol{x}, t)\right) &amp; =\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t) \ v(t) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t) &amp; =\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \Delta_{\boldsymbol{x}} q(\boldsymbol{x}, t) \ v(t) &amp; =\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t) .\end{aligned}$ $\boldsymbol{f}(\boldsymbol{x}, t)$is in fact proportional to the score function: $\begin{aligned} \boldsymbol{f}(\boldsymbol{x}, t) &amp; =v(t) \frac{\nabla_{\boldsymbol{x}} q(\boldsymbol{x}, t)}{q(\boldsymbol{x}, t)} \ &amp; =v(t) \nabla_{\boldsymbol{x}} \log q(\boldsymbol{x}, t) \ &amp; =\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \nabla_{\boldsymbol{x}} \log q(\boldsymbol{x}, t)\end{aligned}$ we recover a family of SDEs whose solution densities have the desired marginals with noise levels $\sigma(t)$for any choice of $g(t)$: $\mathrm{d} \boldsymbol{x}=\left(\frac{1}{2} g(t)^2-\dot{\sigma}(t) \sigma(t)\right) \nabla_{\boldsymbol{x}} \log p(\boldsymbol{x} ; \sigma(t)) \mathrm{d} t+g(t) \mathrm{d} \omega_t$</p> </body></html>